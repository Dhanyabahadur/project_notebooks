{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afceeff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg2\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import re\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7fa51b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from:  ./img_test/train\n",
      "\n",
      "Class type of query image: america-beautiful\n"
     ]
    }
   ],
   "source": [
    "class ImageMatcher:\n",
    "    def __init__(self):\n",
    "        self.pgconn = self.connect_to_database()\n",
    "        self.cursor = self.pgconn.cursor()\n",
    "        \n",
    "    def connect_to_database(self):\n",
    "        try:\n",
    "            pgconn = pg2.connect(\n",
    "                host='localhost',\n",
    "                user='postgres',\n",
    "                password='test',\n",
    "                database='vector_db',\n",
    "                port=5432\n",
    "            )\n",
    "            return pgconn\n",
    "        except psycopg2.InterfaceError as e:\n",
    "            print('{} - connection will be reset'.format(e))\n",
    "            # Close old connection \n",
    "            if pgconn:\n",
    "                if curs:\n",
    "                    curs.close()\n",
    "                pgconn.close()\n",
    "            pgconn = None\n",
    "            cursor = None\n",
    "\n",
    "            # Reconnect \n",
    "            pgconn = psycopg2.connect(user='postgres',\n",
    "                                    password='test',\n",
    "                                    host='localhost',\n",
    "                                    port=5432,\n",
    "                                    database='vector_db'\n",
    "                                    )\n",
    "            return pgconn\n",
    "\n",
    "        #self.curs = self.pgconn.cursor()\n",
    "        self.curs.execute('CREATE EXTENSION IF NOT EXISTS vector')\n",
    "        self.curs.execute(\"ROLLBACK\")\n",
    "        pgconn.commit()\n",
    "\n",
    "        return pgconn\n",
    "\n",
    "    def create_table(self):\n",
    "        self.curs.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS training_data (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            image_path TEXT NOT NULL,\n",
    "            class_type TEXT NOT NULL,\n",
    "            file_name TEXT NOT NULL,\n",
    "            keypoints VECTOR NOT NULL,\n",
    "            descriptors VECTOR NOT NULL\n",
    "        )\n",
    "        \"\"\")\n",
    "        self.pgconn.commit()\n",
    "\n",
    "    def create_query_table(self):\n",
    "        self.curs.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS query_data (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            query_des VECTOR NOT NULL,\n",
    "            query_kp VECTOR NOT NULL\n",
    "        )\n",
    "        \"\"\")\n",
    "        self.pgconn.commit()\n",
    "        \n",
    "        \n",
    "    def imageResizeTrain(self, image):\n",
    "        maxD = 1024\n",
    "        height, width = image.shape\n",
    "        aspectRatio = width / height\n",
    "        if aspectRatio < 1:\n",
    "            newSize = (int(maxD * aspectRatio), maxD)\n",
    "        else:\n",
    "            newSize = (maxD, int(maxD / aspectRatio))\n",
    "        image = cv2.resize(image, newSize)\n",
    "        return image\n",
    "\n",
    "    def imageResizeTest(self, image):\n",
    "        maxD = 1024\n",
    "        height, width, channel = image.shape\n",
    "        aspectRatio = width / height\n",
    "        if aspectRatio < 1:\n",
    "            newSize = (int(maxD * aspectRatio), maxD)\n",
    "        else:\n",
    "            newSize = (maxD, int(maxD / aspectRatio))\n",
    "        image = cv2.resize(image, newSize)\n",
    "        return image\n",
    "\n",
    "    def compute_sift(self, image):\n",
    "        # Create SIFT object and detect keypoints and compute descriptors for the input image\n",
    "        sift = cv2.SIFT_create()\n",
    "        return sift.detectAndCompute(self.imageResizeTrain(cv2.imread(image, cv2.IMREAD_GRAYSCALE)), None)    \n",
    "    \n",
    "    \n",
    "    def string_to_list(self, input_string):\n",
    "        # Split the string by comma and convert each element to float\n",
    "        return [float(x.strip()) for x in input_string.split(',')]\n",
    "\n",
    "    def pad_vector(self, vector, target_dimension):\n",
    "        \"\"\"\n",
    "        Pad the vector with zeros to match the target dimension.\n",
    "        \"\"\"\n",
    "        if len(vector) < target_dimension:\n",
    "            padding = [0] * (target_dimension - len(vector))\n",
    "            vector += padding\n",
    "        return vector\n",
    "\n",
    "    def get_keypoints_descriptors(self, img_folder_path):\n",
    "        print(\"Loading images from: \", img_folder_path)\n",
    "        file_extensions = ['jpg', 'jpeg']\n",
    "        for ext in file_extensions:\n",
    "            for file in glob.glob(f\"{img_folder_path}/**/*.{ext}\", recursive=True):\n",
    "                sift = cv2.SIFT_create()\n",
    "                keypointTemp, descriptorTemp = sift.detectAndCompute(self.imageResizeTrain(cv2.imread(file, cv2.IMREAD_GRAYSCALE)), None)\n",
    "                keypoints = []\n",
    "                descriptors = []\n",
    "                keypoints.append(keypointTemp)\n",
    "                descriptors.append(descriptorTemp)\n",
    "                for i, keypoint in enumerate(keypoints):\n",
    "                    deserializedKeypoints = []\n",
    "                    for point in keypoint:\n",
    "                        temp = (point.pt, point.size, point.angle, \n",
    "                                point.response, point.octave, \n",
    "                                point.class_id)\n",
    "                        deserializedKeypoints.append(temp)\n",
    "                \n",
    "                deserializedKeypoints = \", \".join(map(str, deserializedKeypoints)).replace(\")\", \"\").replace(\"(\", \"\")\n",
    "                deserializedKeypoints = self.string_to_list(deserializedKeypoints)\n",
    "                deserializedKeypoints = deserializedKeypoints[:15900]\n",
    "                deserializedKeypoints = self.pad_vector(deserializedKeypoints, target_dimension=15900)\n",
    "                \n",
    "                descriptors = np.array(descriptors).ravel().tolist()\n",
    "                des_vector = descriptors[:15900]\n",
    "                des_vector = self.pad_vector(des_vector, target_dimension=15900)\n",
    "                \n",
    "                register_vector(self.pgconn)\n",
    "                class_type = os.path.basename(os.path.dirname(file))\n",
    "                file_name = os.path.basename(file)\n",
    "                self.cursor.execute(\"INSERT INTO training_data (image_path, class_type, file_name, keypoints, descriptors) VALUES (%s, %s, %s, %s, %s)\",\n",
    "                        (file, class_type, file_name, deserializedKeypoints, des_vector))\n",
    "                self.pgconn.commit()\n",
    "                #self.cursor.close()\n",
    "                \n",
    "                \n",
    "    def calculate_similarity(self, query_des, query_kp, threshold):\n",
    "        # Insert the query descriptor and keypoint into the database\n",
    "        self.cursor.execute(\"INSERT INTO query_data (query_des, query_kp) VALUES (%s, %s)\", (query_des, query_kp))\n",
    "        self.pgconn.commit()\n",
    "\n",
    "        # Construct the SQL query to calculate similarity\n",
    "        sSQL = \"\"\"\n",
    "    SELECT \n",
    "        training_data.class_type,\n",
    "        training_data.descriptors <-> query_data.query_des AS desc_distance,\n",
    "        training_data.keypoints <-> query_data.query_kp AS kp_distance\n",
    "    FROM \n",
    "        training_data, query_data\n",
    "    WHERE \n",
    "        training_data.descriptors <-> query_data.query_des >= %s\n",
    "    AND\n",
    "        training_data.keypoints <-> query_data.query_kp >= %s\n",
    "    ORDER BY \n",
    "        (training_data.descriptors <-> query_data.query_des,\n",
    "        training_data.keypoints <-> query_data.query_kp) ASC\n",
    "    LIMIT 1;\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the query with threshold and fetch the result\n",
    "        self.cursor.execute(sSQL, (threshold, threshold))\n",
    "        result = self.cursor.fetchone()\n",
    "        # Delete the inserted query data\n",
    "        self.cursor.execute(\"DELETE FROM query_data\")\n",
    "        self.pgconn.commit()\n",
    "\n",
    "        # Check if result is not None\n",
    "        if result is not None:\n",
    "            # Fetch the distances from the result\n",
    "            desc_distance = result[1]\n",
    "            class_type = result[0]\n",
    "\n",
    "            # Combined similarity is just descriptor distance for now\n",
    "            combined_similarity = desc_distance\n",
    "        else:\n",
    "            combined_similarity = 0  # Default similarity if no match found\n",
    "            class_type = \"UNKNOWN\"\n",
    "\n",
    "        return combined_similarity, class_type\n",
    "\n",
    "    def find_validation_image_class_type(self, query_image_path):\n",
    "        sift = cv2.SIFT_create()\n",
    "        keypointTemp, descriptorTemp = sift.detectAndCompute(self.imageResizeTrain(cv2.imread(query_image_path, cv2.IMREAD_GRAYSCALE)), None)\n",
    "        keypoints = []\n",
    "        descriptors = []\n",
    "        keypoints.append(keypointTemp)\n",
    "        descriptors.append(descriptorTemp)\n",
    "        for i, keypoint in enumerate(keypoints):\n",
    "            deserializedKeypoints = []\n",
    "            for point in keypoint:\n",
    "                temp = (point.pt, point.size, point.angle, \n",
    "                        point.response, point.octave, point.class_id)\n",
    "                deserializedKeypoints.append(temp)\n",
    "\n",
    "        deserializedKeypoints = \", \".join(map(str, deserializedKeypoints)).replace(\")\", \"\").replace(\"(\", \"\")\n",
    "        deserializedKeypoints = self.string_to_list(deserializedKeypoints)\n",
    "        query_kp = deserializedKeypoints[:15900]\n",
    "        query_kp = self.pad_vector(query_kp, target_dimension=15900)\n",
    "        descriptors = np.array(descriptors).ravel().tolist()\n",
    "        query_des = descriptors[:15900]\n",
    "        query_des = self.pad_vector(query_des, target_dimension=15900)\n",
    "        threshold = 0  # Set the threshold for similarity\n",
    "    \n",
    "        # Calculate similarity using the provided function\n",
    "        combined_similarity, class_type = self.calculate_similarity(query_des, query_kp, threshold)\n",
    "        return class_type\n",
    "    \n",
    "    \n",
    "\n",
    "# Instantiate the ImageMatcher class\n",
    "image_matcher = ImageMatcher()\n",
    "\n",
    "# Call the get_keypoints_descriptors method to populate the training data\n",
    "train_folder_path = \"./img_test/train\"\n",
    "image_matcher.get_keypoints_descriptors(train_folder_path)\n",
    "\n",
    "# Call the find_validation_image_class_type method to find the class type of the query image\n",
    "query_image_path = \"./img_test/val/beautiful-blessings/beautiful-blessings-check-3.jpeg\"\n",
    "class_type = image_matcher.find_validation_image_class_type(query_image_path)\n",
    "print(\"\\nClass type of query image:\", class_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
